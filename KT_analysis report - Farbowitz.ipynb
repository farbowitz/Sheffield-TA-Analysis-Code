{"cells":[{"cell_type":"markdown","metadata":{"id":"r7bk-4gAIe7v"},"source":["## **KT analysis**\n","*Dan Farbowitz*\n","\n","A note book to explore clearness index calculation and distributions using pvlib.\n","Originally designed by Jamie Taylor, A Buckley\n","\n","First Authored: 2019-11-05\n","\n","Added on importing large data sets, plots, and regressions.\n","\n","Revised: 2020-02-12\n"]},{"cell_type":"markdown","metadata":{"id":"ndLlsjzxI2Nm"},"source":["Install python package"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FoGQtTURJeDG","vscode":{"languageId":"python"}},"outputs":[],"source":["!pip install numpy pandas>1.0 matplotlib pvlib geopy geocoder"]},{"cell_type":"markdown","metadata":{"id":"UGIrXsjcJswI"},"source":["Import modules. force_remount is used because of the need to import from different folders as a result of the number of files involved."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsIHscN_JoOK","vscode":{"languageId":"python"}},"outputs":[],"source":["from datetime import datetime as dt\n","\n","from google.colab import drive\n","drive.mount('drive', force_remount=True)\n","\n","import pytz\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import pvlib\n","from geopy.geocoders import Nominatim\n","import glob\n","import os\n","import json\n","import requests\n","import scipy.stats as sp\n","from sklearn.linear_model import LinearRegression\n","import statsmodels.formula.api as sm \n","from statsmodels.stats.outliers_influence import summary_table\n","from statsmodels.sandbox.regression.predstd import wls_prediction_std\n","pd.set_option('display.max_rows', None)\n"]},{"cell_type":"markdown","metadata":{"id":"Pyd1-AT5KEkp"},"source":["A previous variant used geopy to reverse-lookup the location from its (lat, long) coordinates given in the NREL data.\n","\n","Temperature will be averaged from temperature data later."]},{"cell_type":"markdown","metadata":{"id":"ArZ9pDwvlGmr"},"source":["Due to long wait times in compiling data, split it up by data set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4AB6hgXAzzB","vscode":{"languageId":"python"}},"outputs":[],"source":["#default timezone\n","tz = \"UTC\"\n","#New Import Method for NSRDB data\n","folders = ['/content/drive/MyDrive/KT data/NREL NSRDB Data/Dataset A - Near Boston','/content/drive/MyDrive/KT data/NREL NSRDB Data/Dataset B - Bay Area','/content/drive/MyDrive/KT data/NREL NSRDB Data/Dataset C - Death Valley','/content/drive/MyDrive/KT data/NREL NSRDB Data/Dataset D - NE of Albaquerque','/content/drive/MyDrive/KT data/NREL NSRDB Data/Dataset E - NW of Des Moines','/content/drive/MyDrive/KT data/NREL NSRDB Data/Dataset F - Big Island of Hawaii' ]\n","\n","\n","\n","cells = {}\n","elev_data = {}\n","for folder in folders:\n","  all_files = glob.glob(os.path.join(folder, '*.csv'))\n","  for filename in all_files:\n","  \n","    #extracting relevant information from first 2 lines of original file (necessary because of oddness in NREL data files that gave overflow errors)\n","    paraminfo = pd.read_csv(filename, sep = ',', usecols = ['Elevation', 'Latitude', 'Longitude'], nrows=1)\n","    df = pd.read_csv(filename, header=2)\n","    #add in positional information to dataframe\n","    elevation = paraminfo['Elevation'][0]\n","    latitude = paraminfo['Latitude'][0]\n","    longitude = paraminfo['Longitude'][0]\n","    #elimniating extra 'Unnamed' columns\n","    for i in df.columns:\n","      if i[:2] == 'Un':\n","        df = df.drop([i], axis=1)\n","    #replacing date/time columns with datetime index\n","    df.index = pd.to_datetime(df[df.columns[0:5]])\n","    df = df.drop(['Year', 'Month', 'Day', 'Hour', 'Minute'], axis=1)\n","    #data merging\n","    if (str(latitude) + \",\" + str(longitude)) not in cells:\n","      cells[str(latitude) + \",\" + str(longitude)] = df\n","      elev_data[str(latitude) + \",\" + str(longitude)] = int(elevation)\n","    else:\n","      cells[str(latitude) + \",\" + str(longitude)] = pd.concat([cells[str(latitude) + \",\" + str(longitude)], df])\n","\n","#and sorting\n","for cell in cells:\n","  cells[cell] = cells[cell].sort_index()\n","#double-check that elevation data is correct\n","print(elev_data)\n","  "]},{"cell_type":"markdown","metadata":{"id":"cAoCJOFXKka2"},"source":["Creating a function to return the name of the time interval for labeling."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Mxledy7Lkpo","vscode":{"languageId":"python"}},"outputs":[],"source":["#time-based indices\n","def t_alt(short):\n","  if short == 'H':\n","    return 'Hourly'\n","  elif short == 'D':\n","    return 'Daily'\n","  elif short == 'W':\n","    return 'Weekly'\n","  elif short == 'M':\n","    return 'Monthly'\n","  elif short == 'Q':\n","    return 'Quarterly'\n","  elif short == 'Y':\n","    return 'Annual'\n","  else:\n","    return ''"]},{"cell_type":"markdown","metadata":{"id":"KWX9B-JRLolb"},"source":["etr is the extraterrestrial solar radiation for a given time - but it is not corrected to the horizontal plane (etr_hor) at a particular latitude and longitude. To do this correction we need to use the cosine of the zenith angle (from solpos) at that position."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wMMWVqpMivl","vscode":{"languageId":"python"}},"outputs":[],"source":["#looping data over time periods\n","def get_KT_Charts(dataset, lat, long, elev, interval): \n","  #setting up info\n","  latitude = lat\n","  longitude = long\n","  suptl = str(lat) + \",\" + str(long)\n","  dataset = dataset.tz_localize('UTC')\n","  temperature = dataset['Temperature'].mean()\n","  start = dataset.index[0]\n","  end = dataset.index[-1]\n","  altitude = elev\n","\n","  #using available information to get solar position\n","  times = pd.date_range(start = start, end = end, tz = tz, freq = 'H')\n","  loc = pvlib.location.Location(latitude = latitude, longitude = longitude, altitude=altitude)\n","  solpos = loc.get_solarposition(times, temperature)\n","  #calculating irradiance from solar position, including horizontal component by taking cos(zenith angle) of irradiance data\n","  etr = pvlib.irradiance.get_extra_radiation(times)\n","  zen = solpos[\"apparent_zenith\"]\n","  etr_hor = np.cos(np.radians(zen)) * etr\n","  #setting negative values (nighttime 'irradiance') to 0\n","  etr_hor[etr_hor < 0] = 0\n","  #taking means over time interval\n","  etr_h_hor = etr_hor.resample(interval, label=\"right\").mean()\n","  irr = dataset.GHI.resample(interval, label = 'right').mean()\n","  #define KT, removing out of range samples (and 0 so nighttime doesn't overwhelm histogram)\n","  kt = irr / etr_h_hor\n","  kt[kt > 1.3] = np.nan\n","  kt[kt == 0] = np.nan\n","  #relabel for graphs\n","  t_int = t_alt(interval)\n","  #plotting 3 graphs in a 2x2 grid\n","  grid = plt.GridSpec(2, 2, wspace=0.4, hspace=0.4)\n","  plt.subplot(grid[0,:2])\n","  irr.plot(ylabel='Horizontal Irradiance (W/m^2)', xlabel='Date/Time', figsize = (10, 10))\n","  etr_h_hor.plot(ylabel='Horizontal Irradiance (W/m^2)', xlabel='Date/Time')\n","  plt.legend(labels=['Global', 'Extraterrestrial'])\n","\n","  #KT data\n","  plt.subplot(grid[1, 0])\n","  kt.plot(ylabel='KT Index', xlabel='Date/Time', ylim = (0, 1.4))\n","  \n","  #KT Histogram\n","  plt.subplot(grid[1,1])\n","  plt.hist(kt[kt.notnull()], bins=130, range=(0,1.3))\n","  plt.xlabel('KT Index')\n","  plt.ylabel('Number of occurences')\n","  \n","  plt.suptitle(suptl + ' ' + t_int)\n","  plt.show()\n","\n","#call up charts for each time interval based on location (not used)\n","def KT_loc(data):\n","  t_index = ['H', 'D', 'W', 'M', 'Q']\n","  for j in range(5):\n","    get_KT_Charts(data, t_index[j])\n","\n","#run for all data to check if it matches reasonably\n","for i in cells:\n","  get_KT_Charts(cells[i], float(i.split(\",\")[0]), float(i.split(\",\")[1]), float(elev_data[i]), 'W')"]},{"cell_type":"markdown","metadata":{"id":"U7Ze-Ns0xCRV"},"source":["Using the same method to put KT data together for regression:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZofrJ3qcxGPo","vscode":{"languageId":"python"}},"outputs":[],"source":["def KT_data(dataset, lat, long, altitude, interval): \n","  #setting up info\n","  latitude = lat\n","  longitude = long\n","  dataset = dataset.tz_localize('UTC')\n","  temperature = dataset['Temperature'].mean()\n","  start = dataset.index[0]\n","  end = dataset.index[-1]\n","  #using available information to get solar position\n","  times = pd.date_range(start = start, end = end, tz = tz, freq = \"H\")\n","  loc = pvlib.location.Location(latitude = latitude, longitude = longitude, altitude=altitude)\n","  solpos = loc.get_solarposition(times=times, temperature=temperature)\n","  #calculating irradiance from solar position, including horizontal component by taking cos(zenith angle) of irradiance data\n","  etr = pvlib.irradiance.get_extra_radiation(times)\n","  zen = solpos[\"apparent_zenith\"]\n","  etr_hor = np.cos(np.radians(zen)) * etr\n","  #setting negative values (nighttime 'irradiance') to 0\n","  etr_hor[etr_hor < 0] = 0\n","  #taking means over time interval\n","  etr_h_hor = etr_hor.resample(interval, label=\"right\").mean()\n","  irr = dataset.GHI.resample(interval, label = 'right').mean()\n","  #define KT, removing out of range samples (and 0 so nighttime doesn't overwhelm histogram)\n","  kt = irr / etr_h_hor\n","  kt[kt > 1.3] = np.nan\n","  kt[kt == 0] = np.nan\n","  df = pd.DataFrame({'kt': kt})\n","  return df\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CalzxhQe1Y82","vscode":{"languageId":"python"}},"outputs":[],"source":["#creating KT data for each cell\n","kt_cells = {}\n","for i in cells:\n","   kt_cells[i] = KT_data(cells[i], float(i.split(\",\")[0]), float(i.split(\",\")[1]), float(elev_data[i]), 'D')\n","   #DAS = Days after start, changing to numeric values for regression\n","   kt_cells[i]['DAS'] = (kt_cells[i].index - pd.Timestamp(\"1998-01-01\", tz='UTC')).days\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qyU3taYf1gZp","vscode":{"languageId":"python"}},"outputs":[],"source":["#KT analysis\n","\n","\n","def kt_analysis(dataset, lat, long, interval): \n","  #setting up info\n","  latitude = lat\n","  longitude = long\n","  dataset = dataset.tz_convert('UTC')\n","  kt = dataset['kt']\n","  start = dataset.index[0]\n","  end = dataset.index[-1]\n","  #taking means over time interval\n","  kt_avg = kt.resample(interval, label=\"right\").mean()\n","  kt_avg = pd.DataFrame(kt_avg, columns=['kt'])\n","  #Again using days after start for regression\n","  kt_avg['DAS'] = (kt_avg.index - pd.Timestamp(\"1998-01-01\", tz='UTC')).days\n","\n","  # Following method derived from https://stackoverflow.com/questions/34998772/plotting-confidence-and-prediction-intervals-with-repeated-entries, adapted for linear regression model\n","  #plot with regression line  \n","  x = kt_avg.DAS\n","  y = kt_avg.kt\n","\n","  plt.figure(figsize=(6 * 1.618, 6))\n","  plt.scatter(x,y, s=10, alpha=0.3)\n","  plt.xlabel('Days since 01-01-1998')\n","  plt.ylabel('KT')\n","\n","  # points linearly spaced for predictor variable\n","  x1 = pd.DataFrame({'DAS': np.linspace(kt_avg.DAS.min(), kt_avg.DAS.max(), 100)})\n","\n","\n","  linreg = sm.ols(formula='kt ~ DAS',   data=kt_avg).fit()\n","\n","  # Plots linear bestfit line:\n","\n","\n","  prstd, iv_l, iv_u = wls_prediction_std(linreg)\n","\n","  st, data, ss2 = summary_table(linreg, alpha=0.05)\n","\n","  fittedvalues = data[:,2]\n","  predict_mean_se  = data[:,3]\n","  predict_mean_ci_low, predict_mean_ci_upp = data[:,4:6].T\n","  predict_ci_low, predict_ci_upp = data[:,6:8].T\n","  #data\n","  plt.plot(x, y, 'o')\n","  #linear regression\n","  plt.plot(x1.DAS, linreg.predict(x1), '-', label='Linear Fit  $R^2$=%.2f' % linreg.rsquared)\n","  #prediction interval based on slope\n","  plt.plot(x, predict_mean_ci_low, 'r--', lw=2, label='95% confidence interval')\n","  plt.plot(x, predict_mean_ci_upp, 'r--', lw=2)\n","  #confidence interval based on both coefficients\n","  plt.plot(x, predict_ci_low, 'g--', lw=2, label='95% prediction interval')\n","  plt.plot(x, predict_ci_upp, 'g--', lw=2)\n","  plt.title(\"(\"+str(lat)+\",\"+str(long)+\") \"+t_alt(interval)+ \" sampling\")\n","\n","\n","  plt.legend()\n","\n","\n","  #Commented out, but helps verify statistics\n","  #print(sm.ols(formula = \"kt ~ DAS\", data=kt_avg).fit().summary())\n","  out = {'Location': \"(\"+str(lat)+\", \"+str(long)+\")\", 'Estimated per year change to KT': sm.ols(formula = \"kt ~ DAS\", data=kt_avg).fit().params['DAS']*365.25, 'p-value': linreg.pvalues['DAS'], 'r^2-value':linreg.rsquared}\n","  return out\n","\n","\n","#runs kt_analysis to form a chart of useful value\n","\n","kt_data = pd.DataFrame(columns=['Location', 'Estimated per year change to KT', 'p-value', 'r^2-value'])\n","for i in kt_cells:\n","  kt_data = kt_data.append(kt_analysis(kt_cells[i], float(i.split(\",\")[0]), float(i.split(\",\")[1]), 'Y'), ignore_index=True)\n","kt_data = kt_data.set_index('Location')\n","kt_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IC6b30soi_07","vscode":{"languageId":"python"}},"outputs":[],"source":["#temperature analysis\n","temp_cells = {}\n","\n","def temp_analysis(dataset, lat, long, interval): \n","  #setting up info\n","  latitude = lat\n","  longitude = long\n","  dataset = dataset.tz_localize('UTC')\n","  temperature = dataset['Temperature']\n","  start = dataset.index[0]\n","  end = dataset.index[-1]\n","  #taking means over time interval\n","  temps = temperature.resample(interval, label=\"right\").mean()\n","  temps = pd.DataFrame(temps, columns=['Temperature'])\n","  #Again using days after start for regression\n","  temps['DAS'] = (temps.index - pd.Timestamp(\"1998-01-01\", tz='UTC')).days\n","\n","  # Following method derived from https://stackoverflow.com/questions/34998772/plotting-confidence-and-prediction-intervals-with-repeated-entries, adapted for linear regression model\n","  #plot with regression line  \n","  x = temps.DAS\n","  y = temps.Temperature\n","\n","  plt.figure(figsize=(6 * 1.618, 6))\n","  plt.scatter(x,y, s=10, alpha=0.3)\n","  plt.xlabel('Days since 01-01-1998')\n","  plt.ylabel('Temperature (degC)')\n","\n","  # points linearly spaced for predictor variable\n","  x1 = pd.DataFrame({'DAS': np.linspace(temps.DAS.min(), temps.DAS.max(), 100)})\n","\n","\n","  linreg = sm.ols(formula='Temperature ~ DAS',   data=temps).fit()\n","\n","  # Plots linear bestfit line:\n","\n","\n","  prstd, iv_l, iv_u = wls_prediction_std(linreg)\n","\n","  st, data, ss2 = summary_table(linreg, alpha=0.05)\n","\n","  fittedvalues = data[:,2]\n","  predict_mean_se  = data[:,3]\n","  predict_mean_ci_low, predict_mean_ci_upp = data[:,4:6].T\n","  predict_ci_low, predict_ci_upp = data[:,6:8].T\n","  #data\n","  plt.plot(x, y, 'o')\n","  #linear regression\n","  plt.plot(x1.DAS, linreg.predict(x1), '-', label='Linear Fit  $R^2$=%.2f' % linreg.rsquared)\n","  #prediction interval based on slope\n","  plt.plot(x, predict_mean_ci_low, 'r--', lw=2, label='95% confidence interval')\n","  plt.plot(x, predict_mean_ci_upp, 'r--', lw=2)\n","  #confidence interval based on both coefficients\n","  plt.plot(x, predict_ci_low, 'g--', lw=2, label='95% prediction interval')\n","  plt.plot(x, predict_ci_upp, 'g--', lw=2)\n","  plt.title(\"(\"+str(lat)+\",\"+str(long)+\") \"+t_alt(interval)+ \" sampling\")\n","\n","\n","  plt.legend()\n","\n","\n","  #Commented out, but helps verify statistics\n","  #print(sm.ols(formula = \"Temperature ~ DAS\", data=temps).fit().summary())\n","  out = {'Location': \"(\"+str(lat)+\", \"+str(long)+\")\", 'Estimated per year change (degC)': sm.ols(formula = \"Temperature ~ DAS\", data=temps).fit().params['DAS']*365.25, 'p-value': linreg.pvalues['DAS'], 'r^2-value':linreg.rsquared}\n","  return out\n","\n","\n","#runs temp_analysis to form a chart of useful value\n","temp_data = pd.DataFrame(columns=['Location', 'Estimated per year change (degC)', 'p-value', 'r^2-value'])\n","for i in cells:\n","   temp_data = temp_data.append(temp_analysis(cells[i], float(i.split(\",\")[0]), float(i.split(\",\")[1]), 'M'), ignore_index=True)\n","temp_data = temp_data.set_index('Location')\n","temp_data"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"KT_analysis report - Farbowitz.ipynb","provenance":[{"file_id":"1nuWoWWCdGH0BP9_mOEjHmwMcmXDE9OxN","timestamp":1612862226186},{"file_id":"1YlK6rN-fqEYNpTWy1Us1eL9dDjsacEtr","timestamp":1605648401804}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
